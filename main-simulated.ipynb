{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXAMPLE CODES FOR THE SIMULATED RECONSTRUCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.forward_models.bornapprox import MVProd,MVProd_iterK\n",
    "import src.optimization as opt\n",
    "from src.config import RADAR_SYSTEM_CONFIGS, RSC2params\n",
    "from src.nn_models.unet3D import denoiser\n",
    "\n",
    "from src.utils.stats import psnr3D, snrdB, snrdB2nvar, awgn\n",
    "from src.utils.misc import Scene, super_clear_cuda\n",
    "from src.utils.data import load_dataset, load_json\n",
    "\n",
    "import torch \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donwload the ground truth complex-valued images [1] from https://drive.google.com/drive/folders/1sxosLDMB55ZEjkti-o2d7m3V59jCAe5o?usp=sharing and place them inside \"../data/datasets/IrfanC/\".\n",
    "\n",
    "[1] I. Manisali, O. Oral, and F. S. Oktem, ”Efficient physics-based learned reconstruction methods for real-time 3D near-field MIMO radar imaging”, Digital Signal Processing, vol. 144, p. 104274, 2024, doi: 10.1016/j.dsp.2023.104274."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate the measurements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nfreqs=20 # Number of frequencies used\n",
    "SNR=30 # Signal to noise ratio of the simulated measurements in decibells\n",
    "\n",
    "radar_system_params = RSC2params(RADAR_SYSTEM_CONFIGS[Nfreqs]) #get the radar system parameters\n",
    "A = MVProd( freqs = radar_system_params.freqs, # frequency list\n",
    "            tx_positions = radar_system_params.tx_positions, # transmitter positions\n",
    "            rx_positions = radar_system_params.rx_positions, # receiver positions\n",
    "            x_coords = radar_system_params.x_coords, # discretized x-coordinates\n",
    "            y_coords = radar_system_params.y_coords, # discretized y-coordinates\n",
    "            z_coords = radar_system_params.z_coords, # discretized z-coordinates\n",
    "            path = '', save = False # you can set a path to save the forward model matrix \n",
    "            )\n",
    "\n",
    "# load the ground truth data\n",
    "x_test = load_dataset('IrfanC','test').to(dtype=torch.complex128)\n",
    "\n",
    "# simulate the measurements\n",
    "x=x_test\n",
    "A=A.to('cpu')\n",
    "Ax = A(x)\n",
    "n_var_test = snrdB2nvar(Ax,snrdB=SNR)\n",
    "N_vox=Ax.shape[-1]*Ax.shape[-2]*Ax.shape[-3]\n",
    "eps = torch.sqrt(n_var_test*N_vox) # epsilon values are computed to be fed to CSALSA\n",
    "\n",
    "torch.manual_seed(0) # set seed to add noise\n",
    "y = awgn(Ax.to('cpu'),snrdB=SNR,dtype=torch.complex128) # add noise to measurements\n",
    "\n",
    "print('Forward model matrix shape: ',A.A.shape)\n",
    "print('100*(M/N) = ~{:.2f}'.format(100*A.A.shape[0]*A.A.shape[1]*A.A.shape[2]/(A.A.shape[3]*A.A.shape[4]*A.A.shape[5])))\n",
    "print('y test  avg.  SNR: ',np.round(torch.mean(snrdB(Ax,y-Ax)).item(),2),'dB')\n",
    "print('EPS.  test   avg.: ',np.round(torch.mean(eps).item(),2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "if device != \"cpu\":\n",
    "     super_clear_cuda(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruct the scenes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    model_state_dict= torch.load('trained_model/base_model.pt')\n",
    "\n",
    "    denoiser_config=load_json('trained_model/info.json')['arch']\n",
    "    denoiser_net = denoiser(**denoiser_config)\n",
    "    denoiser_net.load_state_dict(model_state_dict)\n",
    "\n",
    "    solver = opt.NNCG_CSALSA(forward_model=A, denoiser_net=denoiser_net, blind=False, noise_level_map='std', cg_max_iter=5, cg_th=1e-5, zero_phase=False, record=False)\n",
    "    # you can use other denoising networks as well,\n",
    "    # if you plan to use a blind denoiser set \"blind\" to True, \n",
    "    # if your noise level map is the variance of the noise, set \"noise_level_map\" to 'var'\n",
    "    # cg_max_iter is the maximum number of conjugate gradient iterations\n",
    "    # cg_th is the minimum relative improvement on the l2 norm before terminating the conjugate gradient iterations (cg_max_iter has priority over cg_th)\n",
    "    # you should always use zero_phase=False. If true, it enforces real-positive values on reflectivity distribution, which is an incorrect assumption\n",
    "    # by setting record to True, you can store the values of the data fidelity and regularization terms throughout the iterations (may be useful for debugging)\n",
    "\n",
    "\n",
    "    # Other solvers:\n",
    "    # solver = opt.TVCG_CSALSA(forward_model=A, chambolle_iter=5, cg_max_iter=5, cg_th=1e-5, zero_phase=False, record=False)\n",
    "    # solver = opt.l1CG_CSALSA(forward_model=A, cg_max_iter=5, cg_th=1e-5, zero_phase=False, record=False)\n",
    "    # solver = opt.BackProjection(radar_system_params=radar_system_params)\n",
    "    # solver = opt.KirchhoffMigration(radar_system_params=radar_system_params,compansate_limited_aparture=False)\n",
    "    \n",
    "    solver.to(device)\n",
    "    solver.clear_history()\n",
    "\n",
    "    kwargs = {}\n",
    "\n",
    "    # set the algorithm parameters\n",
    "    start_idx=4\n",
    "    batch_size=1\n",
    "    target = torch.abs(x[start_idx:start_idx+batch_size,...]).to(device)\n",
    "    kwargs['y'] = y[start_idx:start_idx+batch_size,...].to(device)\n",
    "    kwargs['eps'] = eps[start_idx:start_idx+batch_size,...].to(device) # epsillon parameter in the paper\n",
    "    kwargs['asynchronous']= True # If you are using GPU and reconstructing with batches, then you should set asynchronous to True (this allows to asynchronously stop the image updates when parallel processing, if set to False the solver will continue the optimization even after some solutions converge, this can create numerical instability)\n",
    "    kwargs['tqdm_active'] = True # Set to True if you want to see an iteration counter\n",
    "    kwargs['K'] = 500 # Kappa parameter in the paper\n",
    "    kwargs['noise_var'] = 3.9e-2 # alpha parameter in the paper\n",
    "    kwargs['max_iter']=30 # set to 10000 for TV and L1 \n",
    "\n",
    "    # run the solver\n",
    "    solver.forward(**kwargs)\n",
    "    \n",
    "    # get estimates (estimates are returned as normalized magnitues, you can access complex valued reconstructions by \"solver.x\")\n",
    "    est = solver.get_estimate().cpu()\n",
    "\n",
    "    # compute the performance\n",
    "    psnrs = psnr3D(target=target,estimation=est).cpu().squeeze().tolist()\n",
    "    \n",
    "    # compute the average performance\n",
    "    avg_psnr = np.mean(psnrs)\n",
    "    print('Average PSNR (dB): ',avg_psnr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene=Scene()\n",
    "scene.show_simulated(x=est,radar_system_params=radar_system_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TCI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
